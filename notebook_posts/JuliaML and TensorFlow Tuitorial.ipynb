{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This is a demonstration of using JuliaML and TensorFlow to train an LSTM network.\nIt is based on  [Aymeric Damien's LSTM tutorial in Python](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb). \nAll the explinations are my own, but the code is generally similar in intent.\nThere are also some differences in terms of network-shape.\n\nThe task is to use LSTM to classify MNIST digits.\nThat is image recognition.\nThe normal way to solve such problems is a ConvNet.\nThis is not a sensible use of LSTM, after all it is not a time series task.\nThe task is made into a time series task, by the images arriving one row at at a time;\nand the network is asked to output which class at the end after seeing the 28th row. \nSo the LSTM network must remember the last 27 prior rows.\nThis is a toy problem to demonstrate that it can.\n"

    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To do this we are going to use a bunch of packages from the [JuliaML Org](https://github.com/JuliaML), as well as a few others.\nA lot of the packages in JuliaML are evolving fast, so somethings here may be wrong.\nYou can install the packages used in this demo by running:\n`Pkg.add.([\"TensorFlow\", \"Distributions\", \"ProgressMeter\", \"MLLabelUtils\", \"MLDataUtils\"])`,\nand `Pkg.clone(\"https://github.com/JuliaML/MLDatasets.jl.git\")`.\nMLDatasets.jl is not yet registers so you need to clone that one.\nAlso right now (24/01/2017), we are using the **dev** branch of MLDataUtils.jl,\nso you will need to do the `git checkout` stuff to make that work,\nbut hopefully very soon that will be merged into master, so just the normal `Pkg.add` will surfice.\nYou also need to install [TensorFlow](https://www.tensorflow.org/get_started/os_setup), as it is not automatically installed by the TensorFlow.jl package.\nWe will go through each package we use in turn. <!--more-->"
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "using TensorFlow\nusing Distributions\nusing ProgressMeter\nusing MLLabelUtils\nusing MLDataUtils\nusing MLDatasets\nusing Base.Test",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We will begin by defining some of the parameters for our network as constants.\nOut network has 28 inputs -- one row of pixels, and each image consists of 28 time steps so each row is shown.\nThe other parameters whould be fairly self explainitory."
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Training Hyper Parameter\nconst learning_rate = 0.001\nconst training_iters = 2 #Just two, becuase I don't have anything to stop overfitting and I don't got all day\nconst batch_size = 256\nconst display_step = 100 #How often to display the \n\n# Network Parameters\nconst n_input = 28 # MNIST data input (img shape: 28*28)\nconst n_steps = 28 # timesteps\nconst n_hidden = 128 # hidden layer num of features\nconst n_classes = 10; # MNIST total classes (0-9 digits)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "10"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We are going to use the MNIST distribution, from the [MLDatasets.jl](https://github.com/JuliaML/MLDatasets.jl/).\nIt is a handy way to get hold of the data.\nThe first time you call one of its data functions it will download the data.\nAfter that it will load it from disk.\nIt is a nice implementation, simply done using `file(path) || download(url, path)` at the start of the method.\nI would like to implement something similar for [CorpusLoaders.jl](https://github.com/oxinabox/CorpusLoaders.jl)\nWe check its shape -- the data is a 3D Array, `(col,row,item)`, and the labels are integers.\nWe also define a quick imshow function to draw ascii art so we cha check it out."
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "const traindata_raw,trainlabels_raw = MNIST.traindata();\n@show size(traindata_raw)\n@show size(trainlabels_raw)\n\nimshow(x) = join(mapslices(join, (x->x ? 'X': ' ').(x'.>0), 2), \"\\n\") |> print\n@show trainlabels_raw[8]\nimshow(traindata_raw[:,:,8])\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "size(traindata_raw) = (28,28,60000)\nsize(trainlabels_raw) = (60000,)\ntrainlabels_raw[8] = 3\n                            \n                            \n                            \n                            \n                            \n           XXXXXXXXXXX      \n         XXXXXXXXXXXXXX     \n         XXXXXXXXXXXXXX     \n         XXXXXXXXXXXXXX     \n         XXXX    XXXXXX     \n                 XXXXX      \n                XXXXXX      \n              XXXXXXXX      \n         XXXXXXXXXXXX       \n        XXXXXXXXXXX         \n        XXXXXXXXXXXX        \n         XXXXXXXXXXX        \n                XXXX        \n                XXXX        \n      XXX      XXXXX        \n     XXXX    XXXXXXX        \n     XXXXXXXXXXXXXX         \n     XXXXXXXXXXXXX          \n     XXXXXXXXXXX            \n      XXXXXXX               \n                            \n                            \n                            ",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We use  [MLLabelUtils.jl](https://github.com/JuliaML/MLLabelUtils.jl/) to encode the labels and [MLDataUtils.jl](https://github.com/JuliaML/MLDataUtils.jl) to segment the labels and the data into minibatchs. That is how those two packages fit together.\nIf it applies to only labelled data, eg Encodings then it is done with MLLabelUtils.\nIf it applies to data in general, eg partitioning the data, the it is done with MLDataUtils.\nThey are nice stand-alone packages that can be chained in with other JuliaML packages,\nor used in a independant system. Which is more like what we are doing here with TensorFlow.jl.\n\n\nWhen it comes to encoding the labels, we use `convertlabel` from MLLabelUtils.\nIts signiture is `convertlabel(output_encoding, input_labels, input_encoding)`.\nWe provide both the desired (output) encoding, and the current (input) encoding.\nThis ensure that the input is interpretted correctly and constantly.\nIf we do not provide the input encoding, then MLDataUtils would infer the encoding.\nThe encoding it would infer (because the input is not strictly positive integers) is that the labels are arbitary.\nIt would thus devise a `NativeLabel` Mapping, based on the order the labels occur in input.\nThat mapping would not be saved anywhere, so when it comes time to encode the test data, we don't know which index corresponds to which label symbol. \nSo we declare the input_label. (Alternatives would be to infor it using `labelenc(labels_raw)` and then record the inferred encoding for later. Or to add 1 to all the raw labels so it is in the range 1:10, which causes the labels to be inferred as `LabelEnc.Indices{Int64,10}()`)\n\nTo break the data down into minibatchs, we use a `BatchView` from MLDataUtils.\nBatchView is an iterator and efficiently returns it back 1 minibatch at a time.\nThere are a few requirement on the input iterator,\nbut a julia Array meets all of them.\nIt also nicely lets you specify which dimention the observations are on,\nbut in ourcase it is the last, which is the default.\nWe will use the data in batchs later, once we have defined the network graph."
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "\"\"\"Makes 1 hot encoded labels.\"\"\"\nencode(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw, LabelEnc.NativeLabels(collect(0:9)))\n\n\nconst trainlabels = BatchView(encode(trainlabels_raw), batch_size)\nconst traindata = BatchView(traindata_raw, batch_size);\n\n@testset \"data_prep\" begin\n    @test encode([4,1,2,3,0]) ==   [ 0  0  0  0  1\n                                     0  1  0  0  0\n                                     0  0  1  0  0\n                                     0  0  0  1  0\n                                     1  0  0  0  0\n                                     0  0  0  0  0\n                                     0  0  0  0  0\n                                     0  0  0  0  0\n                                     0  0  0  0  0\n                                     0  0  0  0  0 ]\n    @test size(first(traindata)) ==  (n_steps, n_input, batch_size)\n    @test size(first(trainlabels)) ==  (n_classes, batch_size)\nend;",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[1m\u001b[34mINFO: The specified values for size and/or count will result in 96 unused data points\n\u001b[0m\u001b[1m\u001b[34mINFO: The specified values for size and/or count will result in 96 unused data points\n\u001b[0m",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\u001b[1m\u001b[37mTest Summary: | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m\u001b[1m\u001b[34mTotal\u001b[0m\n  data_prep   | \u001b[1m\u001b[32m   3  \u001b[0m\u001b[1m\u001b[34m    3\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now to define the network graph, this is done using [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl).\n[TensorFlow](https://www.tensorflow.org/) is basically a linear algebra tool-kit, featuring automatic differentiation, and optimisation methods.\nWhich makes it awesome for implementing neural networks.\nIt does have some neural net specific stuff (A lot of which is in `contrib` rather than core `src`) such as the LSTMCell,\nbut it is a lot more general than just neural networks.\nIt's more like Theano, than it is like Mocha, Caffe or SKLearn.\nThis means is actually flexible enough to be useful for (some) machine learning research, rather than only for apply standard networks.\nWhich is great, because I get tired of doing the backpropergation calculus by hand on weird network topologies.\nBut today we are just going to use it on a standard kind of network, this LSTM. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We begin by defining out variables in a fairly standard way.\nThis is very similar to what you would see in a feedward net, see the [examples from Tensorflow.jl's manual](https://malmaud.github.io/tfdocs/logistic/).\nFor our purposes, TensorFlow has 4 kinda of network elements:\n\n - **Placeholders**, like `X` and `Y_obs` -- these are basically input elements. We declare that this symbol is a Placeholder for data we are going to feed in when we `run` the network\n - **Variables**, like `W`, `B`, and what is hidden inside the `LSTMCell` -- these are things that can be adjusted during training\n - **Derived Values**, like `Y_pred`, `cost`, `accuracy`, `Hs` and `x` -- these nodes hold the values returned from some operation, they can by your output, or they can be steps in the middle of a chain of such operations.\n - **Action Nodes**, like `optimizer`. When these nodes are interacted with (eg Output from `run`), they do *something* to the network. `optimizer` in our adjusts the *Variables* to optimise the value of its function input -- `cost`.\n \nThe last two terms, **Derived Values** and **Action Nodes**, I made up.\nIt has how I think of them, but your probably won't see it in any kind of offical documentation, or in the source code.\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "So we first declare our inputs as Placeholders.\nYou will note that they are being sized into Batchs here.\nWe then define the varaiables `W` and `B`; \nnote that [we use `get_variable` that than declaring it directly](http://stackoverflow.com/q/37098546/179081),\nbecause in general that is the preferred way, and it lets us use the initializer etc.\nWe use the Normal distribution as an initialiser. This comes from [Distributions.jl](https://github.com/JuliaStats/Distributions.jl).\nIt is set higher variance than I would normally use, but it seems to work well enough.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "sess = Session(Graph())\nX = placeholder(Float32, shape=[n_steps, n_input, batch_size])\nY_obs = placeholder(Float32, shape=[batch_size, n_classes])\n\nvariable_scope(\"model\", initializer=Normal(0, 0.5)) do\n    global W = get_variable(\"weights\", [n_hidden, n_classes], Float32)\n    global B = get_variable(\"bias\", [n_classes], Float32)\nend;",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now want to hook the input `X` into an RNN, made using `LSTMCell`s.\nTo do this we need the data to be a list of tensors (matrixs since 2),\nwhere\n\n- each element of the list is a different time step, (i.e. a different row of the each image)\n- going down the second index of the matrix moves within a single input step (i.e. along the same row of the orginal image)\n- and going down the first index puts you on to the next item in the batch.\n\nInitially we have `(steps, observations, items)`, we are going to use `x` repeatedly as a temporary variable.\nWe use `transpose` to reorder the indexes, so that it is  `(steps, items, observations)`.\nThen `reshape` to merge/splice/weave the first two indexes into once index `(steps-items, observations)`.\nThen `spit` to cut along every the first index making a list of tensors `[(items1,observations1), (items2,observations2), ...]`.\nThis feels a bit hacky as a way to do it, but it works.\nI note here that `transpose` feels a little unidiomatic in particuar, since it ise 0-indexed, and need the cast to Int32 (you'll get an errror without that), and since the matching julia function is called `permutedims` -- I would not be surprised if this changed in future versions of TensorFlow.jl."
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Prepare data shape to match `rnn` function requirements\n# Current data input shape: (n_steps, n_input, batch_size) from the way we declared X (and the way the data actually comes)\n# Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n    \nx = transpose(X, Int32.([1, 3, 2].-1)) # Permuting batch_size and n_steps. (the -1 is to use 0 based indexing)\nx = reshape(x, [n_steps*batch_size, n_input]) # Reshaping to (n_steps*batch_size, n_input)\nx = split(1, n_steps, x) # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n@show get_shape.(x);",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "get_shape.(x) = TensorFlow.ShapeInference.TensorShape[TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28],TensorShape[256, 28]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we connect it `LSTMcell` and we put that cell into an `rnn`.\nThe `LSTMcell` makes up all the LSTM machinery, with forget gates etc,\nand the `rnn` basically multiplies them and hooks it up to their `x`.\nIt returns the output hidden layers `Hs` and the `states`. \nWe don't really care about the `states`\nbut `Hs` is a list of **Derived Value** kind of tensors.\nThere is one of them for each of the input steps.\nWe want to hook up only the last one to our next softmax stage, so we do so with `Hs[end]`.\n\nFinally we hook up the output layer to get `Y_pred`.\nUsing a fairly standard softmax formulation.\n[Aymeric Damien's Python code](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3_NeuralNetworks/recurrent_network.ipynb) doesn't seem to use a softmax output.\nI tried without a softmax output and I couldn't get it to work at all.\nY\nThis may be to do with the `rnn` and `LSTMCell` in julia being a little crippled.\nThey don't have the full implementation of the Python API.\nIn particular I couldn't workout a way to initialise the `forget_bias` to one,\nso I am not sure if it is not messing it up and becoming a bit unstable at times.\nAlso, right now there is only support for static `rnn`  rather than the `dynamic_rnn` which all the cool kids apparently use(See *rnn vs. dynamic_rnn*  in [this article](http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/)).\nThis will probably come in time.\n\nSo if all things are correctly setup the shape of the output: `Y_pred` should match the shape of the input `Y_obs`."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "Hs, states = nn.rnn(nn.rnn_cell.LSTMCell(n_hidden), x; dtype=Float32);\nY_pred = nn.softmax(Hs[end]*W + B)\n\n@show get_shape(Y_obs)\n@show get_shape(Y_pred);",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "get_shape(Y_obs) = TensorShape[256, 10]\nget_shape(Y_pred) = TensorShape[256, 10]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally we define the last few nodes of out network.\nThese are the `cost`, for purposes of using to define  the `optimizer`; and the `accuracy`.\nThe cost is defined using the definition of cross-entropy.\nRight now we have to put it in manually, because TensorFlow.jl has not yet implemented that in as `nn.nce_loss` (there is just a stub there).\nSo we use this cross-entropy as the  cost function for a `AdamOptimizer`, to make out `optimizer` node.\n\nWe also make a `accuracy` node for use during reporting.\nThis is done by counting the portion of the outputs `Y_pred`  that match the inputs `Y_obs`.\nUsing the cast-the-boolean-to-a-float-then-take-it's-mean trick.\n\nHere, it is worth metioning that nodes in tensorflow that are not between the supplied input and the requested output are not evaluated.\nThis means that if one does `run(sess, [optimizer], Dict(X=>xs, Y_obs=>ys))` then the `accuracy` node will never be evaluated.\nIt does not need to be evaluated to get the `optimizer` node (but `cost`, does).\nWe will run the network in the next step\n"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "cost = reduce_mean(-reduce_sum(Y_obs.*log(Y_pred), reduction_indices=[1])) #cross entropy\n@show get_shape(Y_obs.*log(Y_pred))\n@show get_shape(cost) #Should be [] as it should be a scalar\n\noptimizer = train.minimize(train.AdamOptimizer(learning_rate), cost)\n\ncorrect_prediction = indmax(Y_obs, 2) .== indmax(Y_pred, 2)\n@show get_shape(correct_prediction)\naccuracy = reduce_mean(cast(correct_prediction, Float32));\n",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "get_shape(Y_obs .* log(Y_pred)) = TensorShape[256, 10]\nget_shape(cost) = TensorShape[]\nget_shape(correct_prediction) = TensorShape[unknown]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally we can run our training.\nSo we go through a zip of traindata and trainlabels we prepared earlier,\nrun the optimizer on each.\nand periodically check the accuracy of that last batch to give status updates.\nIt is all very nice."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": false
      },
      "cell_type": "code",
      "source": "run(sess, initialize_all_variables())\n\nkk=0\nfor jj in 1:training_iters\n    for (xs_a, ys_a) in zip(traindata, trainlabels)\n        xs = collect(xs_a)\n        ys = collect(ys_a)'\n        run(sess, optimizer,  Dict(X=>xs, Y_obs=>ys))\n        kk+=1\n        if kk % display_step == 1\n            train_accuracy, train_cost = run(sess, [accuracy, cost], Dict(X=>xs, Y_obs=>ys))\n            info(\"step $(kk*batch_size), loss = $(train_cost),  accuracy $(train_accuracy)\")\n        end\n    end\nend",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[1m\u001b[34mINFO: step 256, loss = 62.762604,  accuracy 0.1171875\n\u001b[0m\u001b[1m\u001b[34mINFO: step 25856, loss = 29.060556,  accuracy 0.671875\n\u001b[0m\u001b[1m\u001b[34mINFO: step 51456, loss = 15.045149,  accuracy 0.76953125\n\u001b[0m\u001b[1m\u001b[34mINFO: step 77056, loss = 13.506208,  accuracy 0.859375\n\u001b[0m\u001b[1m\u001b[34mINFO: step 102656, loss = 10.518069,  accuracy 0.8671875\n\u001b[0m",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally we check how we are going on the test data.\nHowever, as all our nodes have been defined in terms of batch_size,\nwe are going to need to process the test data in minibatches  also.\nI feel like these should be a cleaner way to do this that that.\n\nThis is a chance to show of the awesomeness that is [ProgressMeter.jl](https://github.com/timholy/ProgressMeter.jl) `@show_progess`.\nThis displace a unicode-art progress bar, marking progress through the iteration.\nVery neat."
    },
    {
      "metadata": {
        "collapsed": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "testdata_raw, testabels_raw = MNIST.testdata()\ntestlabels = BatchView(encode(testabels_raw), batch_size)\ntestdata = BatchView(testdata_raw, batch_size);\n\n\nbatch_accuracies = []\n@showprogress for (ii, (xs_a, ys_a)) in enumerate(zip(testdata, testlabels))\n    xs = collect(xs_a)\n    ys = collect(ys_a)'\n\n    batch_accuracy = run(sess, accuracy, Dict(X=>xs, Y_obs=>ys))\n    #info(\"step $(ii),   accuracy $(batch_accuracy )\")\n    push!(batch_accuracies, batch_accuracy)\nend\n@show mean(batch_accuracies) #Mean of means of consistantly sized batchs is the overall mean",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\u001b[1m\u001b[34mINFO: The specified values for size and/or count will result in 16 unused data points\n\u001b[0m\u001b[1m\u001b[34mINFO: The specified values for size and/or count will result in 16 unused data points\n\u001b[0m",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Progress: 100%|█████████████████████████████████████████| Time: 0:00:06\nmean(batch_accuracies) = 0.90334535f0\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.90334535f0"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "90\\% accuracy, not bad for an unoptimised network -- particularly one as unsuited to the tast as LSTM.\nI hope this introduction the JuliaML and TensorFlow has been enlightening.\nThere is lots of information about TensorFlow online, though to unstand the julia wrapper I had to look at the source-code more ofthen than the its docs. But that will get better with maturity, and the docs line up the the Python API quiet well a lot of the time.\nThe docs for the new version of MLDataUtils are still being finished off (that is the main blocker on it being merged as I understand it).\nHopefully tuitorials like this lets you see how these all fit together to do something useful."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-0.5",
      "display_name": "Julia 0.5.1-pre",
      "language": "julia"
    },
    "language_info": {
      "mimetype": "application/julia",
      "file_extension": ".jl",
      "version": "0.5.1",
      "name": "julia"
    },
    "gist": {
      "id": "",
      "data": {
        "description": "LSTM_tuitorial.ipynb",
        "public": true
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
