{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyone who has been stalking me may know that I have been making a fairly significant number of PR's against [TensorFlow.jl](https://github.com/malmaud/TensorFlow.jl).\n",
    "One thing I am particularly keen on is [making the interface really Julian](https://github.com/malmaud/TensorFlow.jl/projects/2). Taking advantage of the ability to overload julia's great syntax for matrix indexing and operations.\n",
    "I will make another post going into those enhancements sometime in the future; and how great julia's ability to overload things is. Probably after [#209](https://github.com/malmaud/TensorFlow.jl/pull/209) is merged.\n",
    "This post is not directly about those enhancements, but rather about a emergant feature I noticed today.\n",
    "I wrote some code to run in base julia, but just by changing the types to `Tensors` it now runs inside TensorFlow, and on my GPU (potentially).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically this did require [one little PR](https://github.com/malmaud/TensorFlow.jl/pull/213), but it was just adding in the linking code for operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using TensorFlow\n",
    "using Base.Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined a function to determine the which bin-index a continous value belongs it.\n",
    "This is useful if one has discretized a continous range of values; as is done in a histogram.\n",
    "This code lets you know which bin a given input lays within.\n",
    "\n",
    "It comes from my current research interest in [using machine learning around the language of colors](https://github.com/oxinabox/ColoringNames.jl/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_bin"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Determine which bin a continous value belongs in\"\n",
    "function find_bin(value, nbins, range_min=0.0, range_max=1.0)\n",
    "    portion = nbins * (value / (range_max - range_min))\n",
    "\n",
    "    clamp(round(Int, portion), 1, nbins)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mTest Summary: | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m\u001b[1m\u001b[34mTotal\u001b[0m\n",
      "  Find_bin    | \u001b[1m\u001b[32m  26  \u001b[0m\u001b[1m\u001b[34m   26\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base.Test.DefaultTestSet(\"Find_bin\",Any[],26,false)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@testset \"Find_bin\" begin\n",
    "    @test find_bin(0.0, 64) == 1\n",
    "    @test find_bin(1.0, 64) == 64\n",
    "    @test find_bin(0.5, 64) == 32\n",
    "    @test find_bin(0.4999, 64) == 32\n",
    "    @test find_bin(0.5001, 64) == 32\n",
    "\n",
    "    n_bins = 20\n",
    "    for ii in 1.0:n_bins\n",
    "        @test find_bin(ii, 20, 0.0, n_bins) == Int(ii)\n",
    "    end\n",
    "    \n",
    "    @test [10, 11, 19, 2] == find_bin([0.5, 0.51, 0.9, 0.1], 21)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is perfectly nice julia code that runs perfectly happily with the types from `Base`.\n",
    "Both on scalars, and on `Arrays`, via broadcasting.\n",
    "\n",
    "Turns out, it will also run perfectly fine on TensorFlow `Tensors`.\n",
    "This time it will generate an computational graph which can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-04 15:34:12.893787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
      "name: Tesla K40c\n",
      "major: 3 minor: 5 memoryClockRate (GHz) 0.745\n",
      "pciBusID 0000:02:00.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.10GiB\n",
      "2017-05-04 15:34:12.893829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
      "2017-05-04 15:34:12.893835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
      "2017-05-04 15:34:12.893845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)\n",
      "\u001b[1m\u001b[31mWARNING: You are using an old version version of the TensorFlow binary library. It is recommened that you upgrade with Pkg.build(\"TensorFlow\") or various\n",
      "            errors may be encountered.\n",
      " You have 1.0.0 and the new version is 1.0.1.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sess = Session(Graph())\n",
    "\n",
    "obs = placeholder(Float32)\n",
    "bins = find_bin(obs, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess, bins, Dict(obs=>0.1f0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 10\n",
       " 20\n",
       " 25\n",
       " 26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(sess, bins, Dict(obs=>[0.1, 0.2, 0.25, 0.261]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quiet happily run the whole testset from before.\n",
    "Using `constant` to change the inputs into constant `Tensors`.\n",
    "then running the operations to get back the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mTest Summary:    | \u001b[0m\u001b[1m\u001b[32mPass  \u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-04 15:34:16.021916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mTotal\u001b[0m\n",
      "  Find_bin_tensors | \u001b[1m\u001b[32m  26  \u001b[0m\u001b[1m\u001b[34m   26\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Base.Test.DefaultTestSet(\"Find_bin_tensors\",Any[],26,false)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@testset \"Find_bin_tensors\" begin\n",
    "    sess = Session(Graph()) #New graph\n",
    "    \n",
    "    \n",
    "    @test run(sess, find_bin(constant(0.0), 64)) == 1\n",
    "    @test run(sess, find_bin(constant(1.0), 64)) == 64\n",
    "    @test run(sess, find_bin(constant(0.5), 64)) == 32\n",
    "    @test run(sess, find_bin(constant(0.4999), 64)) == 32\n",
    "    @test run(sess, find_bin(constant(0.5001), 64)) == 32\n",
    "\n",
    "    n_bins = 20\n",
    "    for ii in 1.0:n_bins\n",
    "        @test run(sess, find_bin(constant(ii), 20, 0.0, n_bins)) == Int(ii)\n",
    "    end\n",
    "    \n",
    "    @test [10, 11, 19, 2] ==  run(sess, find_bin(constant([0.5, 0.51, 0.9, 0.1]), 21))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It just works.  \n",
    "In general that is a great thing to say about any piece of technology.  \n",
    "Be it a library, a programming language, or a electronic device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wether or not it is particular useful to be running integer cliping and rounding operations on the GPU is another question.\n",
    "It is certainly nice to be able to include this operation as part of a larger network defination.\n",
    "\n",
    "\n",
    "The really great thing about this, is that the library maker does not need to know anything about TensorFlow, at all.\n",
    "I certainly didn't have it in mind when I wrote the function.\n",
    "The function just works on any type, so long as the user provides suitable methods for the functions it uses via multiple dispatch.\n",
    "This is basically [Duck-Typing](https://en.wikipedia.org/wiki/Duck_typing).\n",
    "if if it provides methods for `quack` and for `waddle`,\n",
    "then I can treat it like a `Duck`, even if it is a `Goose`.\n",
    "\n",
    "It would not work if I had have written say:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_bin_strictly_typed (generic function with 3 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function find_bin_strictly_typed(value::Float64, nbins::Int, range_min::Float64=0.0, range_max::Float64=1.0)\n",
    "    portion = nbins * (value / (range_max - range_min))\n",
    "\n",
    "    clamp(round(Int, portion), 1, nbins)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching find_bin_strictly_typed(::TensorFlow.Tensor{Float64}, ::Int64)\u001b[0m\nClosest candidates are:\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64, \u001b[1m\u001b[31m::Float64\u001b[0m, \u001b[1m\u001b[31m::Float64\u001b[0m) at In[8]:2\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64, \u001b[1m\u001b[31m::Float64\u001b[0m) at In[8]:2\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64) at In[8]:2\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching find_bin_strictly_typed(::TensorFlow.Tensor{Float64}, ::Int64)\u001b[0m\nClosest candidates are:\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64, \u001b[1m\u001b[31m::Float64\u001b[0m, \u001b[1m\u001b[31m::Float64\u001b[0m) at In[8]:2\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64, \u001b[1m\u001b[31m::Float64\u001b[0m) at In[8]:2\n  find_bin_strictly_typed(\u001b[1m\u001b[31m::Float64\u001b[0m, ::Int64) at In[8]:2\u001b[0m",
      ""
     ]
    }
   ],
   "source": [
    "run(sess, find_bin_strictly_typed(constant(0.4999), 64)) == 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moral of the story is *don't over constrain your function parameters*.  \n",
    "Leave you functions loosely typed, and you may get free functionality later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.1",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
